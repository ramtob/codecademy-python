{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is Jeopardy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is slightly different than others you have encountered thus far. Instead of a step-by-step tutorial, this project contains a series of open-ended requirements which describe the project you'll be building. There are many possible ways to correctly fulfill all of these requirements, and you should expect to use the internet, Codecademy, and/or other resources when you encounter a problem that you cannot easily solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will work to write several functions that investigate a dataset of _Jeopardy!_ questions and answers. Filter the dataset for topics that you're interested in, compute the average difficulty of those questions, and train to become the next Jeopardy champion!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to complete this project, you should have completed the Pandas lessons in the <a href=\"https://www.codecademy.com/learn/paths/analyze-data-with-python\">Analyze Data with Python Skill Path</a>. You can also find those lessons in the <a href=\"https://www.codecademy.com/learn/data-processing-pandas\">Data Analysis with Pandas course</a> or the <a href=\"https://www.codecademy.com/learn/paths/data-science/\">Data Scientist Career Path</a>.\n",
    "\n",
    "Finally, the <a href=\"https://www.codecademy.com/learn/practical-data-cleaning\">Practical Data Cleaning</a> course may also be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We've provided a csv file containing data about the game show _Jeopardy!_ in a file named `jeopardy.csv`. Load the data into a DataFrame and investigate its contents. Try to print out specific columns.\n",
    "\n",
    "   Note that in order to make this project as \"real-world\" as possible, we haven't modified the data at all - we're giving it to you exactly how we found it. As a result, this data isn't as \"clean\" as the datasets you normally find on Codecademy. More specifically, there's something odd about the column names. After you figure out the problem with the column names, you may want to rename them to make your life easier for the rest of the project.\n",
    "   \n",
    "   In order to display the full contents of a column, we've added this line of code for you:\n",
    "   \n",
    "   ```py\n",
    "   pd.set_option('display.max_colwidth', None)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mred text\u001b[0m\n",
      "\u001b[32mgreen text\u001b[0m\n",
      "\u001b[33myellow text\u001b[0m\n",
      "\u001b[33mThis is a comment\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# taken from https://medium.com/ai-does-it-better/print-colored-text-in-python-enhance-terminal-output-b90aede058c8\n",
    "def print_colored(text, color, end='\\n'):\n",
    "    colors = {'red': '\\x1b[31m', 'green': '\\x1b[32m', 'yellow': '\\x1b[33m', 'blue': '\\x1b[34m'}\n",
    "    reset = '\\x1b[0m'\n",
    "    sys.stdout.write(colors.get(color, '') + text + reset + end)\n",
    "\n",
    "print_comment = lambda text: print_colored(text, color='yellow')\n",
    "\n",
    "print_colored('red text', color='red')\n",
    "print_colored('green text', color='green')\n",
    "print_colored('yellow text', color='yellow')\n",
    "print_comment('This is a comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mColumns names:\u001b[0m\n",
      "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
      "       ' Question', ' Answer'],\n",
      "      dtype='object')\n",
      "\u001b[33mFixing columns names\u001b[0m\n",
      "\u001b[33mFirst five rows, with fixed columns names\u001b[0m\n",
      "   show_number    air_date      round                         Category value  \\\n",
      "0         4680  2004-12-31  Jeopardy!                          HISTORY  $200   \n",
      "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
      "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
      "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
      "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
      "\n",
      "                                                                                                      question  \\\n",
      "0             For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory   \n",
      "1  No. 2: 1912 Olympian; football star at Carlisle Indian School; 6 MLB seasons with the Reds, Giants & Braves   \n",
      "2                     The city of Yuma in this state has a record average of 4,055 hours of sunshine each year   \n",
      "3                         In 1963, live on \"The Art Linkletter Show\", this company served its billionth burger   \n",
      "4     Signer of the Dec. of Indep., framer of the Constitution of Mass., second President of the United States   \n",
      "\n",
      "       answer  \n",
      "0  Copernicus  \n",
      "1  Jim Thorpe  \n",
      "2     Arizona  \n",
      "3  McDonald's  \n",
      "4  John Adams  \n"
     ]
    }
   ],
   "source": [
    "df_jeopardy = pd.read_csv('jeopardy.csv')\n",
    "print_comment('Columns names:')\n",
    "print(df_jeopardy.columns)\n",
    "print_comment('Fixing columns names')\n",
    "df_jeopardy.rename(columns={'Show Number': 'show_number', ' Air Date': 'air_date', ' Round': 'round', 'Category': 'category', \n",
    "                            ' Value': 'value', ' Question': 'question', ' Answer': 'answer'}, inplace=True)\n",
    "print_comment('First five rows, with fixed columns names')\n",
    "print(df_jeopardy.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function that filters the dataset for questions that contains all of the words in a list of words. For example, when the list `[\"King\", \"England\"]` was passed to our function, the function returned a DataFrame of 49 rows. Every row had the strings `\"King\"` and `\"England\"` somewhere in its `\" Question\"`.\n",
    "\n",
    "   Test your function by printing out the column containing the question of each row of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTest result contains 74 rows\u001b[0m\n",
      "6337     In retaliation for Viking raids, this \"Unready\" king of England attacks Norse areas of the Isle of Man\n",
      "9191                   This king of England beat the odds to trounce the French in the 1415 Battle of Agincourt\n",
      "13454                                      It's the number that followed the last king of England named William\n",
      "14912         This country's King Louis IV was nicknamed \"Louis From Overseas\" because he was raised in England\n",
      "18076           In 1199 this crusader king of England was mortally wounded while besieging the castle of Chalus\n",
      "Name: question, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def filter_by_words_in_question(df, list_of_words):\n",
    "    all_words_are_in_string = lambda s: all([word.lower() in s.lower().split(' ') for word in list_of_words])\n",
    "    return df[df.question.apply(all_words_are_in_string)]\n",
    "\n",
    "test_words_list = [\"King\", \"England\"]\n",
    "test_result = filter_by_words_in_question(df_jeopardy, test_words_list)\n",
    "print_comment('Test result contains {} rows'.format(len(test_result)))\n",
    "print(test_result.head(5).question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Test your original function with a few different sets of words to try to find some ways your function breaks. Edit your function so it is more robust.\n",
    "\n",
    "   For example, think about capitalization. We probably want to find questions that contain the word `\"King\"` or `\"king\"`.\n",
    "   \n",
    "   You may also want to check to make sure you don't find rows that contain substrings of your given words. For example, our function found a question that didn't contain the word `\"king\"`, however it did contain the word `\"viking\"` &mdash; it found the `\"king\"` inside `\"viking\"`. Note that this also comes with some drawbacks &mdash; you would no longer find questions that contained words like `\"England's\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mMaking searches case insensitive by string.lower() function is comparisons\u001b[0m\n",
      "\u001b[33mMaking searches for whole words only by split()-ting the searched string into a list of words\u001b[0m\n",
      "\n",
      "6337     In retaliation for Viking raids, this \"Unready\" king of England attacks Norse areas of the Isle of Man\n",
      "9191                   This king of England beat the odds to trounce the French in the 1415 Battle of Agincourt\n",
      "13454                                      It's the number that followed the last king of England named William\n",
      "14912         This country's King Louis IV was nicknamed \"Louis From Overseas\" because he was raised in England\n",
      "18076           In 1199 this crusader king of England was mortally wounded while besieging the castle of Chalus\n",
      "Name: question, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print_comment('Making searches case insensitive by string.lower() function is comparisons')\n",
    "print_comment('Making searches for whole words only by split()-ting the searched string into a list of words')\n",
    "print()\n",
    "print(filter_by_words_in_question(df_jeopardy, [\"king\", \"england\"]).head(5).question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We may want to eventually compute aggregate statistics, like `.mean()` on the `\" Value\"` column. But right now, the values in that column are strings. Convert the`\" Value\"` column to floats. If you'd like to, you can create a new column with float values.\n",
    "\n",
    "   While most of the values in the `\" Value\"` column represent a dollar amount as a string, note that some do not &mdash; these values will need to be handled differently!\n",
    "\n",
    "   Now that you can filter the dataset of question, use your new column that contains the float values of each question to find the \"difficulty\" of certain topics. For example, what is the average value of questions that contain the word `\"King\"`?\n",
    "   \n",
    "   Make sure to use the dataset that contains the float values as the dataset you use in your filtering function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(jeopardy_df.value[jeopardy_df.value.apply(lambda s: s[0] != '$')])\n",
    "# jeopardy_df.value.describe()\n",
    "\n",
    "def value_to_float(str):\n",
    "    if str == 'no value':\n",
    "        return 0\n",
    "    else:\n",
    "        # We convert ',' in order to cover values such as '$2,000'\n",
    "        return float(str[1:].replace(',', '')) \n",
    "\n",
    "df_jeopardy['value_float'] = df_jeopardy.value.apply(value_to_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount and mean value for questions with the words ['king'] is:\n",
      "2075 805.4698795180723\n",
      "The amount and mean value for questions with the words ['queen'] is:\n",
      "818 756.7237163814181\n",
      "The amount and mean value for questions with the words ['flag'] is:\n",
      "616 681.0064935064935\n"
     ]
    }
   ],
   "source": [
    "def check_difficulty_by_words_in_question(df, words):\n",
    "    result = filter_by_words_in_question(df, words)\n",
    "    print('The amount and mean value for questions with the words {} is:'.format(words))\n",
    "    print(len(result), result.value_float.mean())\n",
    "\n",
    "check_difficulty_by_words_in_question(df_jeopardy, ['king'])\n",
    "check_difficulty_by_words_in_question(df_jeopardy, ['queen'])\n",
    "check_difficulty_by_words_in_question(df_jeopardy, ['flag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write a function that returns the count of unique answers to all of the questions in a dataset. For example, after filtering the entire dataset to only questions containing the word `\"King\"`, we could then find all of the unique answers to those questions. The answer \"Henry VIII\" appeared 55 times and was the most common answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of answers 'Henry VIII'\n",
      "85\n",
      "Questions containing the words ['king']\n",
      "No of unique answers\n",
      "1165\n",
      "No of answers 'Henry VIII'\n",
      "41\n",
      "Questions containing the words ['queen']\n",
      "No of unique answers\n",
      "494\n",
      "Questions containing the words ['flag']\n",
      "No of unique answers\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "def count_unique_answers(df):\n",
    "    return df.answer.nunique()\n",
    "\n",
    "print(\"No of answers 'Henry VIII'\")\n",
    "print(len(jeopardy_df[jeopardy_df.answer == 'Henry VIII']))\n",
    "print(\"Questions containing the words ['king']\")\n",
    "dataset = filter_by_words_in_question(df_jeopardy, ['king'])\n",
    "print(\"No of unique answers\")\n",
    "print(count_unique_answers(dataset))\n",
    "print(\"No of answers 'Henry VIII'\")\n",
    "print(len(dataset[dataset.answer == 'Henry VIII']))\n",
    "print(\"Questions containing the words ['queen']\")\n",
    "dataset = filter_by_words_in_question(df_jeopardy, ['queen'])\n",
    "print(\"No of unique answers\")\n",
    "print(count_unique_answers(dataset))\n",
    "print(\"Questions containing the words ['flag']\")\n",
    "dataset = filter_by_words_in_question(df_jeopardy, ['flag'])\n",
    "print(\"No of unique answers\")\n",
    "print(count_unique_answers(dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Explore from here! This is an incredibly rich dataset, and there are so many interesting things to discover. There are a few columns that we haven't even started looking at yet. Here are some ideas on ways to continue working with this data:\n",
    "\n",
    " * Investigate the ways in which questions change over time by filtering by the date. How many questions from the 90s use the word `\"Computer\"` compared to questions from the 2000s?\n",
    " * Is there a connection between the round and the category? Are you more likely to find certain categories, like `\"Literature\"` in Single Jeopardy or Double Jeopardy?\n",
    " * Build a system to quiz yourself. Grab random questions, and use the <a href=\"https://docs.python.org/3/library/functions.html#input\">input</a> function to get a response from the user. Check to see if that response was right or wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many record between 2000 and 2010 ?\n",
      "123852\n",
      "How many record between 1990 and 2000 ?\n",
      "56745\n",
      "How many record between 1990 and 2000, question containing [\"king\"] ?\n",
      "614\n"
     ]
    }
   ],
   "source": [
    "def filter_by_date(df, start_date, end_date):\n",
    "    return df[(df.air_date > start_date) & (df.air_date < end_date)]\n",
    "\n",
    "print('How many record between 2000 and 2010 ?')\n",
    "print(len(filter_by_date(df_jeopardy, '2000-01-01', '2010-01-01')))\n",
    "print('How many record between 1990 and 2000 ?')\n",
    "print(len(filter_by_date(df_jeopardy, '1990-01-01', '2000-01-01')))\n",
    "print('How many record between 1990 and 2000, question containing [\"king\"] ?')\n",
    "print(len(filter_by_date(filter_by_words_in_question(df_jeopardy, ['king']), '1990-01-01', '2000-01-01')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Compare your program to our <a href=\"https://content.codecademy.com/PRO/independent-practice-projects/jeopardy/jeopardy_solution.zip\">sample solution code</a> - remember, that your program might look different from ours (and probably will) and that's okay!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Great work! Visit <a href=\"https://discuss.codecademy.com/t/this-is-jeopardy-challenge-project-python-pandas/462365\">our forums</a> to compare your project to our sample solution code. You can also learn how to host your own solution on GitHub so you can share it with other learners! Your solution might look different from ours, and that's okay! There are multiple ways to solve these projects, and you'll learn more by seeing others' code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'in <string>' requires string as left operand, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mabd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mabd is great\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'in <string>' requires string as left operand, not list"
     ]
    }
   ],
   "source": [
    "['abd'] in 'abd is great'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
